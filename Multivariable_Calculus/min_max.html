<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2025-06-18 Wed 09:21 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Min/Max Problems</title>
<meta name="author" content="Lin Jiang" />
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" href="/style.css" type="text/css"/>
<script>
  window.MathJax = {
    tex: {
      ams: {
        multlineWidth: '85%'
      },
      tags: 'ams',
      tagSide: 'right',
      tagIndent: '.8em'
    },
    chtml: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    svg: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    output: {
      font: 'mathjax-modern',
      displayOverflow: 'overflow'
    }
  };
</script>

<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
<div id="preamble" class="status">
<div class="breadcrumb"><a href="/">Home</a> <span>â†’</span> <a href="/Multivariable_Calculus/index.html">Multivariable Calculus</a></div>
</div>
<div id="content" class="content">
<h1 class="title">Min/Max Problems</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#orgf8c879a">1. Linear Approximations</a></li>
<li><a href="#org658312f">2. Min/Max Problems</a>
<ul>
<li><a href="#org13517b2">2.1. Saddle Point</a></li>
</ul>
</li>
<li><a href="#orga5201e8">3. Least-Squares Interpolation</a></li>
</ul>
</div>
</div>
<div id="outline-container-orgf8c879a" class="outline-2">
<h2 id="orgf8c879a"><span class="section-number-2">1.</span> Linear Approximations</h2>
<div class="outline-text-2" id="text-1">
<p>
Just like with one variable, we can also do linear approximations on two or more variables. If we change \(x\) by a small amount \(\Delta x\), and \(y\) by a small amount \(\Delta y\), then we can say that if \(z=f(x,y)\):
</p>

<p>
\[
\Delta z \approx f_x \Delta x + f_y \Delta y
\]
</p>

<p>
The intuition for this is that the effects add up. By changing \(x\) by a small amount, and then changing \(y\) by a small amount, those changes to \(z\) add up to give us this formula. This is known as a <b>linear approximation</b> because the partial derivatives are representations of tangent <i>lines</i>:
</p>


<div id="org5bbf022" class="figure">
<p><img src="../static/min_max1.png" alt="min_max1.png" />
</p>
</div>

<p>
As you can see, when we combine the two tangent lines from each of our partial derivatives, they form a <i>tangent plane</i>. The linear approximation assumes that for small changes, the graph of our function is approximately equal to this tangent plane.
</p>

<p>
We can also find what exactly this tangent plane's equation is. First, we can find equations that describe the tangent lines created by the two partial derivatives. We shall assume that \(\frac{\partial f}{\partial x}(x_0,y_0) = a\) and \(\frac{\partial f}{\partial y}(x_0,y_0) = b\).
</p>

<p>
For the partial derivative with respect to \(x\), this tells us the slope of the tangent line as \(y\) is held constant. The tangent line's independent variable is \(x\), while its dependent variable is \(z\), and its slope is \(a\). Finally, we know that the point \((x_0,z_0)\) is on the line. Therefore, we can say that:
</p>

<p>
\[
  L_1 = \begin{cases}
z = z_0 + a(x-x_0) \\
y = y_0
\end{cases}
\]
</p>

<p>
Similarly for the second tangent line:
</p>

<p>
\[
  L_2 = \begin{cases}
z = z_0 + a(y-y_0) \\
x = x_0
\end{cases}
\]
</p>

<p>
Since these equations are when the variables \(y\) and \(x\) are held constant, they can be seen as independent of each other. Together, these two lines determine a plane, which is given by:
</p>

<p>
\[
z = z_0 + a(x-x_0) + b(y-y_0)
\]
</p>
</div>
</div>
<div id="outline-container-org658312f" class="outline-2">
<h2 id="org658312f"><span class="section-number-2">2.</span> Min/Max Problems</h2>
<div class="outline-text-2" id="text-2">
<p>
The first observation we shall make is that <i>at a local minimum or maximum</i>, \(f_x=0\) <i>and</i> \(f_y=0\). This can be seen as because if either partial derivative is not 0, then you can still move in that direction to obtain a value that is either greater than or less than the current value, thus making it not a minimum of maximum.
</p>

<p>
More generally, we call \((x_0,y_0)\) to be a <b>critical point</b> of \(f\) if \(f_x(x_0,y_0)=0\) and \(f_y(x_0,y_0)=0\). To find these critical points, we can take the partial derivatives, set their results to zero, and solve their resulting system of equations for the points.
</p>
</div>
<div id="outline-container-org13517b2" class="outline-3">
<h3 id="org13517b2"><span class="section-number-3">2.1.</span> Saddle Point</h3>
<div class="outline-text-3" id="text-2-1">
<p>
It is interesting to note that in three dimensions, there could be a case where a critical point is <i>neither a local min or a local max</i>. This is known as a <b>saddle point</b> (so-called because it looks like a saddle, see below), where moving along one direction would be a local minimum, yet moving along the other direction would be a local maximum:
</p>


<div id="org84615eb" class="figure">
<p><img src="../static/min_max2.png" alt="min_max2.png" />
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-orga5201e8" class="outline-2">
<h2 id="orga5201e8"><span class="section-number-2">3.</span> Least-Squares Interpolation</h2>
<div class="outline-text-2" id="text-3">
<p>
Oftentimes in scientific research, a set of discrete data points is collected and plotted, and we want to obtain a line of best fit through those points, \(y=ax+b\). In other words, we want to solve for the unknowns \(a\) and \(b\).
</p>

<p>
In order to do this, we will have to come up with a definition of what "best" means: how we want to minimize the deviations between each data point and our line of best fit (deviations being the vertical distances). There are many possible answers, but the most universally accepted one is that we want to minimize <i>the sum of the squares of the deviations</i>: this is <b>least-squares interpolation</b>.
</p>

<p>
Now, given each of our data points \((x_i,y_i)\), using our definition of "best" we can set up the following function to minimize:
</p>

<p>
\[
D(a,b) = \sum (y_i - (ax_i + b))^2
\]
</p>

<p>
To find the critical point \((a,b)\) where it is at the minimum, we take the partial derivatives:
</p>

\begin{aligned}
\frac{\partial D}{\partial a} &= \sum 2(y_i - (ax_i+b))(-x_i) = 0  \\
\frac{\partial D}{\partial b} &= \sum 2(y_i - (ax_i+b))(-1) = 0
\end{aligned}

<p>
Simplifying,
</p>

\begin{aligned}
\frac{\partial D}{\partial a} &= \sum (x_i^2a + x_ib - x_iy_i) = 0  \\
\frac{\partial D}{\partial b} &= \sum (x_ia + b - y_i) = 0
\end{aligned}

<p>
We can rewrite this as:
</p>

\begin{aligned}
\left(\sum x_i^2\right)a + \left(\sum x_i\right)b &= \sum (x_iy_i) \\
\left(\sum x_i\right)a + nb &= \sum(y_i)
\end{aligned}

<p>
Realize that once you plug in all of the data points as numbers, this comes out to be a 2x2 linear system, which we can solve for \((a,b)\).
</p>
</div>
</div>
</div>
<div id="postamble" class="status">
<div class="footer">
               <p>Author: Lin Jiang</p>
             </div>
             <div class="last-modified">
               Last modified: 2025-06-18 09:21
             </div>
</div>
</body>
</html>
